{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nationalhymnen: Aggregieren und Aufbereiten der Daten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ressourcen: \n",
    "* [Wikipedia](https://de.wikipedia.org/Liste_der_Nationalhymnen): In der Wikipedia sind fast alle Nationalhymnen erfasst -- oftmals inklusive einer Übersetzung in die deutsche Sprache. Da die Liedtexte nicht einheitlich strukturiert sind, ist beim Auslesen Handarbeit nötig. \n",
    "* [Midi-Datenbank](https://www.kaggle.com/awesomepgm/national-anthems-of-every-country): Datenbank mit allen Midi-Dateien. \n",
    "* [Nationalanthems.info](http://www.nationalanthems.info/Texte): In der Sammlung von Nationalanthems.info sind Hintergrundinformationen zu Nationalhymnen erfasst. Verfügbar ist auch der Text sowie teilweise Übersetzungen ins Englische."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fürs Herunterladen der Rohdaten aus der Wikipedia. \n",
    "import wikipedia\n",
    "wikipedia.set_lang(\"de\")\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from time import sleep\n",
    "\n",
    "# Für die Datenaufbereitung. \n",
    "import re\n",
    "from langdetect import detect\n",
    "from os import system\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Übersicht über die Nationalhymnen aus der Wikipedia wird geladen. \n",
    "r = wikipedia.page('Liste der Nationalhymnen')\n",
    "s = BeautifulSoup(r.html(), 'lxml')\n",
    "t = s.find('table', {'class': 'wikitable'})\n",
    "tr = t.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenstellen der Links zu den Wikipedia-Seiten der Nationalhymnen. \n",
    "link_dict = dict()\n",
    "for t in tr[1:]: \n",
    "    tds = t.find_all('td')\n",
    "    land = tds[0].find('a')['title']\n",
    "    link_song = 'https://de.wikipedia.org' + tds[1].find('a')['href']\n",
    "    link_dict[land] = link_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herunterladen der Texte der Nationalhymnen. \n",
    "lyrics_dict = dict()\n",
    "probleme = list()\n",
    "\n",
    "for l in link_dict.keys():\n",
    "    sleep(2)\n",
    "    try:\n",
    "        r = get(link_dict[l])\n",
    "        s = BeautifulSoup(r.content, 'lxml')\n",
    "        liedtext = s.find_all('div', {'class': 'poem'})\n",
    "        liedtext = [x.find('p').text.strip() for x in liedtext]\n",
    "        lyrics_dict[l] = liedtext\n",
    "    except:\n",
    "        print('Problem bei', l)\n",
    "        probleme.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behalten werden bloss die deutschsprachigen Texte. \n",
    "for l in lyrics_dict.keys():\n",
    "    try:\n",
    "        sp = [detect(x) for x in lyrics_dict[l]]\n",
    "        n = 0 \n",
    "        temp_list = list()\n",
    "        for s in sp:\n",
    "            if s == 'de':\n",
    "                temp_list.append(lyrics_dict[l][n])\n",
    "            n += 1\n",
    "        if len(temp_list) > 0:\n",
    "            lyrics_dict[l] = temp_list\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verweise aus der Wikipedia, Strophen-Angaben etc. werden entfernt.\n",
    "for l in lyrics_dict.keys():\n",
    "    t = '\\n'.join(lyrics_dict[l])\n",
    "    t = re.sub('Strophe\\w\\d', '', t)\n",
    "    t = re.sub('\\(\\d{1,2}\\)', '', t)\n",
    "    t = re.sub('\\[\\d{1,2}\\]', '', t)\n",
    "    lyrics_dict[l] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die einzelnen Texte werden abgespeichert. \n",
    "for l in lyrics_dict.keys():\n",
    "    with open('daten/' + l + '.txt', 'w') as f:\n",
    "        f.write(lyrics_dict[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Texte werden manuell bearbeitet. \n",
    "alle_länder = list(lyrics_dict.keys())\n",
    "#ok = list()\n",
    "for l in [x for x in alle_länder if x not in ok]:\n",
    "    system('google-chrome ' + link_dict[l] + ' &')\n",
    "    system('gedit daten/' + l + '.txt')\n",
    "    ok.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eine Tabelle mit den Verweisen zu den Dateien wird kreiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eine Tabelle mit den Infos zu den Daten wird kreiert. \n",
    "df = pd.DataFrame.from_dict(link_dict, orient='index')\n",
    "df.columns = ['link_wikipedia']\n",
    "df['text'] = df.index + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Englische Länderbezeichnung wird hinzugefügt. \n",
    "df_ländernamen = pd.read_html('https://www.101languages.net/german/country-names-german/')[0]\n",
    "df = pd.merge(df.reset_index(), df_ländernamen, left_on='index', right_on='German', how='left').set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Verweis zur (wahrscheinlich entsprechenden) Midi-Datei wird angefügt. \n",
    "f = listdir('midi/')\n",
    "\n",
    "temp_dict = dict()\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        temp_dict[index] = process.extractOne(row['English'], [x.replace('.mid', '').capitalize() for x in f])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "temp_dict = {key:val for key, val in temp_dict.items() if val[1] > 85}\n",
    "df = pd.merge(df, pd.DataFrame.from_dict(temp_dict, orient='index'), left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Verweis zur (wahrscheinlich entsprechenden) Flagge wird angefügt. \n",
    "f = listdir('flaggen/')\n",
    "\n",
    "temp_dict = dict()\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        temp_dict[index] = process.extractOne(row['English'], [x.replace('_flag.png', '') for x in f])\n",
    "    except:\n",
    "        pass\n",
    "temp_dict = {key:val for key, val in temp_dict.items() if val[1] > 85}\n",
    "df = pd.merge(df, pd.DataFrame.from_dict(temp_dict, orient='index'), left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['wikipedia', 'text', 'englisch', 'deutsch', 'midi', 'midi_wahrscheinlichkeit', 'flagge', 'flagge_wahrscheinlichkeit']\n",
    "df = df[['wikipedia', 'text', 'midi', 'flagge']]\n",
    "df['flagge'] = df['flagge'].apply(lambda x: str(x).lower() + '_flag.png')\n",
    "df['midi'] = df['midi'].apply(lambda x: str(x).lower() + '.mid')\n",
    "df.to_csv('länderübersicht.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javaldx: Could not find a Java Runtime Environment!\r\n",
      "Please ensure that a JVM and the package libreoffice-java-common\r\n",
      "is installed.\r\n",
      "If it is already installed then try removing ~/.config/libreoffice/4/user/config/javasettings_Linux_*.xml\r\n",
      "Warning: failed to read path from javaldx\r\n"
     ]
    }
   ],
   "source": [
    "!libreoffice länderübersicht.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afghanistan\n",
      "Croatia\n"
     ]
    }
   ],
   "source": [
    "# Im Midi-Datensatz fehlen einige Länder. Deshalb wird ein zweiter Datensatz hinzugefügt. \n",
    "midi_links = dict()\n",
    "for n in range(1,3):\n",
    "    r = get('https://www.midiworld.com/search/' + str(n) + '/?q=national%20anthems')\n",
    "    s = BeautifulSoup(r.content, 'lxml')\n",
    "    li = s.find_all('ul')[1].find_all('li')\n",
    "    c = re.search('(.*) \\(National Anthems\\)', li[0].text).group(1)\n",
    "    print(c)\n",
    "    l = li[0].find('a')['href']\n",
    "    midi_links[c] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Afghanistan': 'https://www.midiworld.com/download/4056',\n",
       " 'Croatia': 'https://www.midiworld.com/download/4086'}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.midiworld.com/download/4086'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li[0].find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
